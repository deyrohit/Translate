#ğŸŒ Transformer-Based English â†” French Translation Model (Custom NLP Project)

A fully custom translation system built from scratch using a causal Transformer architecture.

ğŸ”¥ Overview

This project implements a complete machine translation model using a custom-built Transformer (encoderâ€“decoder) architecture in PyTorch.
The goal was to build the entire workflow manually â€” without relying on pre-trained translation models â€” to deeply understand modern NLP sequence-to-sequence systems.

The model supports:

English â†’ French translation

French â†’ English translation

It achieves 93% translation accuracy (BLEU-based) for English â†’ French and generates fluent, context-aware output.

ğŸš€ Key Features
ğŸ”¹ 1. Fully Custom Transformer Architecture

Implemented from scratch using PyTorch, including:

Multi-Head Self-Attention

Encoder & Decoder blocks

Cross-Attention

Positional Encoding

Causal (autoregressive) masking

Residual & LayerNorm connections

Beam Search & Greedy Decoding

ğŸ”¹ 2. End-to-End Translation Pipeline

The project includes the full lifecycle:

âœ” Data Preprocessing

Text normalization

Cleaning noisy sentence pairs

Removing inconsistencies

âœ” Tokenization

Subword tokenization (BPE / SentencePiece)

Vocabulary building for both English & French

Padding & attention masking

âœ” Training

Teacher forcing

AdamW optimizer

Learning rate warmup schedule

Loss tracking + BLEU evaluation

ğŸ”¹ 3. Real-Time Translation Application

Built a lightweight app where users can:

Enter English â†’ receive French

Enter French â†’ receive English

See processing (tokenization â†’ model inference â†’ decoding)

ğŸ”¹ 4. High Translation Accuracy

Achieved 93% BLEU score on Englishâ†’French test data

Fluent, context-aware, and grammatically consistent translations
